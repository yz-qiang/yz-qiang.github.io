---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Zhiqiang Yuan is currently a Ph.D. candidate at Fudan University. 
As a member of <a href="http://www.se.fudan.edu.cn/">CodeWisdom Group</a>, he holds a valuable opportunity to work under the guidance of <a href="https://cspengxin.github.io/">Prof. Xin Peng</a> and <a href="https://yilinglou.github.io/index.html"> Prof. Yiling Lou </a>.
His research primarily focuses on the intersection of Software Engineering (SE) and Artificial Intelligence (AI), with a specific emphasis on the interplay between AI for Software Engineering (AI4SE) and Software Engineering for AI (SE4AI).
His primary interest is leveraging advanced Artificial Intelligence methodologies, such as large language models and knowledge graphs, to address software engineering challenges and tackle the software engineering problems prevalent in AI applications and scenarios.


# üî• News
- [July 2023] Check out our preprint for evaluating instruction-tuned LLMs on code comprehension and generation tasks. <a href="https://arxiv.org/pdf/2308.01240.pdf" class="btn btn--info btn--xs">Preprint</a>
- [May 2023] Check out our preprint on ChatGPT-based unit test generation. <a href="https://arxiv.org/pdf/2305.04207.pdf" class="btn btn--info btn--xs">Preprint</a> 


# üìù Publications 


- <p><a href="https://arxiv.org/abs/2308.01240"><strong style="color:#003366;"> [Preprint]</strong></a>
  Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation.<br>
   <span class="italic"><strong>Zhiqiang Yuan</strong>, Junwei Liu, Qiancheng Zi, Mingwei Liu, Xin Peng, Yiling Lou</span>
  </p>



- <p>No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation.<br>
    <span class="italic"><strong>Zhiqiang Yuan</strong>, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin Wang, Yixuan Chen, Xin Peng</span>
    <a href="https://arxiv.org/abs/2305.04207" class="btn btn--info btn--xs">Preprint</a></p>

- <p>SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval.<br>
    <span class="italic">Qing Huang, Dianshu Liao, Zhenchang Xing, <strong>Zhiqiang Yuan</strong>, Qinghua Lu, Xiwei Xu, Jiaxing Lu.</span>
    <a href="https://arxiv.org/abs/2212.08221" class="btn btn--info btn--xs">Preprint</a></p>

- <p>Prompt-tuned Code Language Model as a Neural Knowledge Base for Type Inference in Statically-Typed Partial Code.<br>
    <span class="italic">Qing Huang, <strong>Zhiqiang Yuan</strong>, Zhenchang Xing, Xiwei Xu, Liming Zhu, Qinghua Lu</span>
    <a href="https://dl.acm.org/doi/10.1145/3551349.3556912" class="btn btn--info btn--xs">ASE 2022</a></p>
    
- <p>1+1>2: Programming Know-What and Know-How Knowledge Fusion, Semantic Enrichment and Coherent Application.<br>
    <span class="italic">Qing Huang, <strong>Zhiqiang Yuan</strong>, Zhenchang Xing, Zhengkang Zuo, Changjing Wang, Xin Xia</span>
    <a href="https://ieeexplore.ieee.org/abstract/document/9894095" class="btn btn--info btn--xs">TSC 2022</a></p>





# üí¨ Invited Talks
- *2022.10*,  Presentation paper at the ASE'22.  \| [\[video\]](https://www.bilibili.com/video/BV1mV4y1L7c5/?share_source=copy_web&vd_source=e7a1b4e73c4b3ccf3228ca017ba2a9f9/)
